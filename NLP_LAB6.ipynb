{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name- Aditya Kumar Tiwari\n",
    "### Roll no.- MSA23023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NLP Lab 6:** Named Entity Recognition (NER) with Language Models\n",
    "\n",
    "**Objective:** Implement a NER system using transformers and evaluate its performance\n",
    "on identifying and classifying named entities in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from seqeval.metrics import classification_report\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERSystem:\n",
    "    def __init__(self, model_name=\"dslim/bert-base-NER\"):\n",
    "        \"\"\"Initialize the NER system with a pre-trained model.\"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "        self.ner_pipeline = pipeline(\n",
    "            \"ner\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            aggregation_strategy=\"simple\"\n",
    "        )\n",
    "        \n",
    "    def predict(self, text):\n",
    "        \"\"\"Perform NER prediction on input text.\"\"\"\n",
    "        return self.ner_pipeline(text)\n",
    "    \n",
    "    def format_results(self, results):\n",
    "        \"\"\"Format NER results for better readability.\"\"\"\n",
    "        formatted = []\n",
    "        for entity in results:\n",
    "            formatted.append({\n",
    "                'entity': entity['word'],\n",
    "                'type': entity['entity_group'],\n",
    "                'confidence': f\"{entity['score']:.4f}\",\n",
    "                'start': entity['start'],\n",
    "                'end': entity['end']\n",
    "            })\n",
    "        return formatted\n",
    "    \n",
    "    def _convert_to_bio_tags(self, text, entities):\n",
    "        \"\"\"\n",
    "        Convert model outputs to BIO tagging scheme.\n",
    "        Improved to handle token alignment properly.\n",
    "        \"\"\"\n",
    "        # Tokenize text\n",
    "        words = text.split()\n",
    "        bio_tags = ['O'] * len(words)\n",
    "        \n",
    "        # Create character to token map\n",
    "        char_to_word = {}\n",
    "        current_pos = 0\n",
    "        for i, word in enumerate(words):\n",
    "            word_len = len(word)\n",
    "            for j in range(current_pos, current_pos + word_len):\n",
    "                char_to_word[j] = i\n",
    "            current_pos += word_len + 1  # +1 for space\n",
    "            \n",
    "        # Assign BIO tags\n",
    "        for entity in entities:\n",
    "            try:\n",
    "                start_word = char_to_word[entity['start']]\n",
    "                end_word = char_to_word[min(entity['end'] - 1, len(text) - 1)] + 1\n",
    "                \n",
    "                for i in range(start_word, end_word):\n",
    "                    if i == start_word:\n",
    "                        bio_tags[i] = f\"B-{entity['entity_group']}\"\n",
    "                    else:\n",
    "                        bio_tags[i] = f\"I-{entity['entity_group']}\"\n",
    "            except KeyError:\n",
    "                continue  # Skip if character position mapping fails\n",
    "                \n",
    "        return bio_tags\n",
    "    \n",
    "    def evaluate_on_dataset(self, test_data):\n",
    "        \"\"\"\n",
    "        Evaluate NER system on a test dataset.\n",
    "        Fixed to ensure consistent token counts.\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        true_labels = []\n",
    "        \n",
    "        for text, annotations in tqdm(test_data):\n",
    "            # Get predicted entities\n",
    "            pred = self.predict(text)\n",
    "            \n",
    "            # Convert to BIO tags\n",
    "            pred_labels = self._convert_to_bio_tags(text, pred)\n",
    "            \n",
    "            # Ensure prediction length matches ground truth\n",
    "            if len(pred_labels) == len(annotations):\n",
    "                predictions.append(pred_labels)\n",
    "                true_labels.append(annotations)\n",
    "            else:\n",
    "                print(f\"Warning: Skipping example due to length mismatch. \"\n",
    "                      f\"Text: {text}\")\n",
    "                print(f\"Predicted length: {len(pred_labels)}, \"\n",
    "                      f\"True length: {len(annotations)}\")\n",
    "                \n",
    "        # Generate evaluation report\n",
    "        return classification_report(\n",
    "            true_labels,\n",
    "            predictions,\n",
    "            digits=4,\n",
    "            zero_division=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER Analysis Results:\n",
      "\n",
      "Text: Microsoft CEO Satya Nadella spoke at a conference in New York last week.\n",
      "\n",
      "Detected Entities:\n",
      "- Microsoft (ORG) [Confidence: 0.9989]\n",
      "- Satya Nadella (PER) [Confidence: 0.9859]\n",
      "- New York (LOC) [Confidence: 0.9993]\n",
      "\n",
      "Text: The European Union signed a trade deal with Singapore worth $50 billion.\n",
      "\n",
      "Detected Entities:\n",
      "- European Union (ORG) [Confidence: 0.9994]\n",
      "- Singapore (LOC) [Confidence: 0.9998]\n",
      "\n",
      "Text: Tesla's Elon Musk announced plans to build a new factory in Berlin, Germany.\n",
      "\n",
      "Detected Entities:\n",
      "- Tesla (ORG) [Confidence: 0.9787]\n",
      "- El (ORG) [Confidence: 0.9994]\n",
      "- ##on Musk (ORG) [Confidence: 0.9930]\n",
      "- Berlin (LOC) [Confidence: 0.9996]\n",
      "- Germany (LOC) [Confidence: 0.9997]\n",
      "\n",
      "Evaluation Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 12.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Skipping example due to length mismatch. Text: Microsoft CEO Satya Nadella spoke at a conference in New York\n",
      "Predicted length: 11, True length: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC     1.0000    1.0000    1.0000         1\n",
      "         ORG     1.0000    1.0000    1.0000         1\n",
      "\n",
      "   micro avg     1.0000    1.0000    1.0000         2\n",
      "   macro avg     1.0000    1.0000    1.0000         2\n",
      "weighted avg     1.0000    1.0000    1.0000         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize NER system\n",
    "    ner_system = NERSystem()\n",
    "    \n",
    "    # Example texts for testing\n",
    "    test_texts = [\n",
    "        \"Microsoft CEO Satya Nadella spoke at a conference in New York last week.\",\n",
    "        \"The European Union signed a trade deal with Singapore worth $50 billion.\",\n",
    "        \"Tesla's Elon Musk announced plans to build a new factory in Berlin, Germany.\"\n",
    "    ]\n",
    "    \n",
    "    # Process each text and display results\n",
    "    print(\"NER Analysis Results:\")\n",
    "    for text in test_texts:\n",
    "        print(f\"\\nText: {text}\")\n",
    "        results = ner_system.predict(text)\n",
    "        formatted_results = ner_system.format_results(results)\n",
    "        \n",
    "        print(\"\\nDetected Entities:\")\n",
    "        for entity in formatted_results:\n",
    "            print(f\"- {entity['entity']} ({entity['type']}) \"\n",
    "                  f\"[Confidence: {entity['confidence']}]\")\n",
    "    \n",
    "    # Example test dataset with annotations (simplified)\n",
    "    test_dataset = [\n",
    "        (\n",
    "            \"Microsoft CEO Satya Nadella spoke at a conference in New York\",\n",
    "            ['B-ORG', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC']\n",
    "        ),\n",
    "        (\n",
    "            \"Tesla announced new factory in Berlin\",\n",
    "            ['B-ORG', 'O', 'O', 'O', 'O', 'B-LOC']\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Evaluate on test dataset\n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    evaluation_results = ner_system.evaluate_on_dataset(test_dataset)\n",
    "    print(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
