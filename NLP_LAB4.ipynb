{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name- Aditya Kumar Tiwari\n",
    "### Roll no.- MSA23023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NLP Lab 4:** Word Sense Disambiguation Task\n",
    "\n",
    "**Objective:** Implement a knowledge-based Word Sense Disambiguation system using the Lesk algorithm and evaluate its performance on ambiguous words in context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Remove punctuation and stopwords, convert to lowercase.\"\"\"\n",
    "    # Tokenize and convert to lowercase\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords and punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lesk_algorithm(context_sentence, ambiguous_word):\n",
    "    \"\"\"\n",
    "    Implement the Lesk algorithm for word sense disambiguation.\n",
    "    \n",
    "    Args:\n",
    "        context_sentence (str): The sentence containing the ambiguous word\n",
    "        ambiguous_word (str): The word to be disambiguated\n",
    "    \n",
    "    Returns:\n",
    "        best_sense: The WordNet sense that best matches the context\n",
    "    \"\"\"\n",
    "    # Preprocess the context sentence\n",
    "    context = set(preprocess_text(context_sentence))\n",
    "    \n",
    "    # Get all possible senses of the ambiguous word\n",
    "    word_senses = wn.synsets(ambiguous_word)\n",
    "    \n",
    "    if not word_senses:\n",
    "        return None\n",
    "    \n",
    "    # Find the sense with maximum overlap\n",
    "    max_overlap = 0\n",
    "    best_sense = word_senses[0]  # default to first sense\n",
    "    \n",
    "    for sense in word_senses:\n",
    "        # Create signature from definition and examples\n",
    "        signature = set(preprocess_text(sense.definition()))\n",
    "        \n",
    "        # Add examples to signature\n",
    "        for example in sense.examples():\n",
    "            signature.update(set(preprocess_text(example)))\n",
    "        \n",
    "        # Calculate overlap between context and signature\n",
    "        overlap = len(context.intersection(signature))\n",
    "        \n",
    "        # Update best sense if current overlap is greater\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            best_sense = sense\n",
    "            \n",
    "    return best_sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_wsd(test_cases):\n",
    "    \"\"\"\n",
    "    Evaluate the WSD system on multiple test cases.\n",
    "    \n",
    "    Args:\n",
    "        test_cases: List of tuples (sentence, ambiguous_word, correct_sense_key)\n",
    "    \n",
    "    Returns:\n",
    "        accuracy: Percentage of correct disambiguations\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = len(test_cases)\n",
    "    \n",
    "    for sentence, word, correct_sense_key in test_cases:\n",
    "        predicted_sense = lesk_algorithm(sentence, word)\n",
    "        if predicted_sense and predicted_sense.name() == correct_sense_key:\n",
    "            correct += 1\n",
    "    \n",
    "    return (correct / total) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual WSD Results:\n",
      "\n",
      "Context: The bank of the river was muddy.\n",
      "Ambiguous word: bank\n",
      "Predicted sense: bank.n.01\n",
      "Definition: sloping land (especially the slope beside a body of water)\n",
      "\n",
      "Context: I need to bank the money.\n",
      "Ambiguous word: bank\n",
      "Predicted sense: depository_financial_institution.n.01\n",
      "Definition: a financial institution that accepts deposits and channels the money into lending activities\n",
      "\n",
      "Context: The bass guitar sounds great.\n",
      "Ambiguous word: bass\n",
      "Predicted sense: bass.s.01\n",
      "Definition: having or denoting a low vocal or instrumental range\n",
      "\n",
      "Context: I caught a huge bass in the lake.\n",
      "Ambiguous word: bass\n",
      "Predicted sense: bass.s.01\n",
      "Definition: having or denoting a low vocal or instrumental range\n",
      "\n",
      "Overall Accuracy: 75.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lenovo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\lenovo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Download required NLTK resources\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    \n",
    "    # Test cases with sentences containing ambiguous words\n",
    "    test_cases = [\n",
    "        (\"The bank of the river was muddy.\", \"bank\", \"bank.n.01\"),\n",
    "        (\"I need to bank the money.\", \"bank\", \"depository_financial_institution.n.01\"),\n",
    "        (\"The bass guitar sounds great.\", \"bass\", \"bass.s.01\"),\n",
    "        (\"I caught a huge bass in the lake.\", \"bass\", \"bass.n.07\")\n",
    "    ]\n",
    "    \n",
    "    # Test individual cases\n",
    "    print(\"Individual WSD Results:\")\n",
    "    for sentence, word, _ in test_cases:\n",
    "        sense = lesk_algorithm(sentence, word)\n",
    "        print(f\"\\nContext: {sentence}\")\n",
    "        print(f\"Ambiguous word: {word}\")\n",
    "        print(f\"Predicted sense: {sense.name()}\")\n",
    "        print(f\"Definition: {sense.definition()}\")\n",
    "    \n",
    "    # Evaluate overall performance\n",
    "    accuracy = evaluate_wsd(test_cases)\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implemented Lesk algorithm shows reasonable performance in disambiguating word senses:\n",
    "\n",
    "1. Strengths:\n",
    "   - Successfully distinguishes between financial and geographical senses of \"bank\"\n",
    "   - Effectively handles different parts of speech for the same word\n",
    "   - Considers both definitions and examples for better context matching\n",
    "\n",
    "2. Limitations:\n",
    "   - Reliance on exact word overlap might miss semantic relationships\n",
    "   - Performance depends heavily on the quality of context provided\n",
    "   - Limited by WordNet's coverage of word senses\n",
    "\n",
    "3. Potential Improvements:\n",
    "   - Incorporate word embeddings for semantic similarity\n",
    "   - Add weights to different context words based on their importance\n",
    "   - Implement sense frequency information from corpus statistics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
